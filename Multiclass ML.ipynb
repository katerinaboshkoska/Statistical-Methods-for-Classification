{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Multiclass dataset.csv', encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deal_id                   int64\n",
       "total_deals               int64\n",
       "deal_type                object\n",
       "deal_start_date          object\n",
       "contract_length         float64\n",
       "industry                 object\n",
       "usage_cycle               int64\n",
       "active_deals              int64\n",
       "deal_subtype             object\n",
       "business_model           object\n",
       "account_age               int64\n",
       "contract_value          float64\n",
       "total_discount          float64\n",
       "mrr                     float64\n",
       "change_in_mrr           float64\n",
       "pricing_category         object\n",
       "average_usage           float64\n",
       "geographic_region        object\n",
       "billing_location         object\n",
       "customer_status          object\n",
       "contribution_percent    float64\n",
       "payment_terms            object\n",
       "payment_method           object\n",
       "employee_count          float64\n",
       "target                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 25 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   deal_id               4898 non-null   int64  \n",
      " 1   total_deals           4898 non-null   int64  \n",
      " 2   deal_type             4271 non-null   object \n",
      " 3   deal_start_date       4898 non-null   object \n",
      " 4   contract_length       4819 non-null   float64\n",
      " 5   industry              4879 non-null   object \n",
      " 6   usage_cycle           4898 non-null   int64  \n",
      " 7   active_deals          4898 non-null   int64  \n",
      " 8   deal_subtype          4898 non-null   object \n",
      " 9   business_model        4871 non-null   object \n",
      " 10  account_age           4898 non-null   int64  \n",
      " 11  contract_value        4898 non-null   float64\n",
      " 12  total_discount        4880 non-null   float64\n",
      " 13  mrr                   4898 non-null   float64\n",
      " 14  change_in_mrr         4896 non-null   float64\n",
      " 15  pricing_category      4898 non-null   object \n",
      " 16  average_usage         2899 non-null   float64\n",
      " 17  geographic_region     4898 non-null   object \n",
      " 18  billing_location      4745 non-null   object \n",
      " 19  customer_status       4898 non-null   object \n",
      " 20  contribution_percent  4872 non-null   float64\n",
      " 21  payment_terms         4898 non-null   object \n",
      " 22  payment_method        4709 non-null   object \n",
      " 23  employee_count        4605 non-null   float64\n",
      " 24  target                4898 non-null   object \n",
      "dtypes: float64(8), int64(5), object(12)\n",
      "memory usage: 956.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deal_id</th>\n",
       "      <th>total_deals</th>\n",
       "      <th>contract_length</th>\n",
       "      <th>usage_cycle</th>\n",
       "      <th>active_deals</th>\n",
       "      <th>account_age</th>\n",
       "      <th>contract_value</th>\n",
       "      <th>total_discount</th>\n",
       "      <th>mrr</th>\n",
       "      <th>change_in_mrr</th>\n",
       "      <th>average_usage</th>\n",
       "      <th>contribution_percent</th>\n",
       "      <th>employee_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4819.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4.898000e+03</td>\n",
       "      <td>4880.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4896.000000</td>\n",
       "      <td>2899.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3722.523683</td>\n",
       "      <td>9.744794</td>\n",
       "      <td>12.310230</td>\n",
       "      <td>9.791956</td>\n",
       "      <td>0.080441</td>\n",
       "      <td>357.201102</td>\n",
       "      <td>3.448865e+04</td>\n",
       "      <td>-0.025024</td>\n",
       "      <td>2818.743310</td>\n",
       "      <td>55.333433</td>\n",
       "      <td>0.428051</td>\n",
       "      <td>0.861695</td>\n",
       "      <td>396.756569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2031.542058</td>\n",
       "      <td>4.097071</td>\n",
       "      <td>2.266914</td>\n",
       "      <td>4.596014</td>\n",
       "      <td>0.347783</td>\n",
       "      <td>340.581298</td>\n",
       "      <td>1.189149e+05</td>\n",
       "      <td>1.261623</td>\n",
       "      <td>9574.665107</td>\n",
       "      <td>3986.011176</td>\n",
       "      <td>0.672384</td>\n",
       "      <td>0.569989</td>\n",
       "      <td>1041.531706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-20.428600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-172879.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.430000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2026.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>2.490000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3742.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>6.003990e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5436.750000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>1.959375e+04</td>\n",
       "      <td>0.376350</td>\n",
       "      <td>1622.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7438.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2436.000000</td>\n",
       "      <td>3.633691e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>260032.790000</td>\n",
       "      <td>65579.170000</td>\n",
       "      <td>11.760000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7570.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           deal_id  total_deals  contract_length  usage_cycle  active_deals  \\\n",
       "count  4898.000000  4898.000000      4819.000000  4898.000000   4898.000000   \n",
       "mean   3722.523683     9.744794        12.310230     9.791956      0.080441   \n",
       "std    2031.542058     4.097071         2.266914     4.596014      0.347783   \n",
       "min       5.000000     2.000000         1.000000     1.000000      0.000000   \n",
       "25%    2026.250000     6.000000        12.000000    12.000000      0.000000   \n",
       "50%    3742.500000    10.000000        12.000000    12.000000      0.000000   \n",
       "75%    5436.750000    13.000000        12.000000    12.000000      0.000000   \n",
       "max    7438.000000    29.000000        48.000000    36.000000      5.000000   \n",
       "\n",
       "       account_age  contract_value  total_discount            mrr  \\\n",
       "count  4898.000000    4.898000e+03     4880.000000    4898.000000   \n",
       "mean    357.201102    3.448865e+04       -0.025024    2818.743310   \n",
       "std     340.581298    1.189149e+05        1.261623    9574.665107   \n",
       "min       0.000000    0.000000e+00      -20.428600       0.000000   \n",
       "25%      54.000000    2.490000e+03        0.000000     210.000000   \n",
       "50%     362.000000    6.003990e+03        0.000000     500.335000   \n",
       "75%     388.000000    1.959375e+04        0.376350    1622.500000   \n",
       "max    2436.000000    3.633691e+06        1.000000  260032.790000   \n",
       "\n",
       "       change_in_mrr  average_usage  contribution_percent  employee_count  \n",
       "count    4896.000000    2899.000000           4872.000000     4605.000000  \n",
       "mean       55.333433       0.428051              0.861695      396.756569  \n",
       "std      3986.011176       0.672384              0.569989     1041.531706  \n",
       "min   -172879.160000       0.000000            -20.430000        0.000000  \n",
       "25%         0.000000       0.030000              0.860000       16.000000  \n",
       "50%         0.000000       0.180000              0.930000       37.000000  \n",
       "75%         0.000000       0.580000              0.960000      210.000000  \n",
       "max     65579.170000      11.760000              1.000000     7570.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           deal_id  total_deals  contract_length  usage_cycle  active_deals  \\\n",
      "count  4483.000000  4483.000000      4409.000000  4483.000000   4483.000000   \n",
      "mean   3665.531787     9.746152        12.226582     9.604952      0.064020   \n",
      "std    2023.574099     4.055866         1.950537     4.605435      0.269954   \n",
      "min       5.000000     2.000000         1.000000     1.000000      0.000000   \n",
      "25%    1971.000000     6.000000        12.000000    12.000000      0.000000   \n",
      "50%    3669.000000    10.000000        12.000000    12.000000      0.000000   \n",
      "75%    5350.500000    13.000000        12.000000    12.000000      0.000000   \n",
      "max    7437.000000    29.000000        48.000000    36.000000      3.000000   \n",
      "\n",
      "       account_age  contract_value  total_discount            mrr  \\\n",
      "count  4483.000000    4.483000e+03     4467.000000    4483.000000   \n",
      "mean    367.662503    2.467943e+04       -0.037662    2043.298911   \n",
      "std     335.455176    9.164760e+04        1.300627    7274.079618   \n",
      "min       0.000000    4.990000e+02      -20.428600       0.000000   \n",
      "25%      77.000000    2.400000e+03        0.000000     200.000000   \n",
      "50%     363.000000    5.820000e+03        0.000000     488.000000   \n",
      "75%     391.000000    1.560000e+04        0.371400    1310.250000   \n",
      "max    2436.000000    3.633691e+06        0.997800  260032.790000   \n",
      "\n",
      "       change_in_mrr  average_usage  contribution_percent  employee_count  \n",
      "count    4481.000000    2645.000000           4483.000000     4209.000000  \n",
      "mean       13.326447       0.414926              0.914383      383.167498  \n",
      "std      2510.240304       0.678270              0.063698     1024.552961  \n",
      "min   -109065.840000       0.000000              0.710000        0.000000  \n",
      "25%         0.000000       0.030000              0.880000       16.000000  \n",
      "50%         0.000000       0.160000              0.930000       35.000000  \n",
      "75%         0.000000       0.550000              0.960000      200.000000  \n",
      "max     45200.000000      11.760000              1.000000     7570.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_outliers(df, columns):\n",
    "    for column in columns:\n",
    "        Q1 = df[column].quantile(0.25) \n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1 \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "columns_to_clean = ['contribution_percent']\n",
    "df= remove_outliers(df, columns_to_clean)\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with maximum values removed.\n"
     ]
    }
   ],
   "source": [
    "for column in float_columns:\n",
    "    max_value = df[column].max()\n",
    "    df = df[df[column] != max_value]\n",
    "\n",
    "print(\"Rows with maximum values removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(df, column):\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define bounds\n",
    "    lower_bound = Q1 - 2 * IQR\n",
    "    upper_bound = Q3 + 2 * IQR\n",
    "    \n",
    "    # Cap the values\n",
    "    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "column_to_cap = 'contribution_percent'  # Replace with your column\n",
    "df = cap_outliers(df, column_to_cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deal_id                    0\n",
       "total_deals                0\n",
       "deal_type                599\n",
       "deal_start_date            0\n",
       "contract_length           72\n",
       "industry                  14\n",
       "usage_cycle                0\n",
       "active_deals               0\n",
       "deal_subtype               0\n",
       "business_model            18\n",
       "account_age                0\n",
       "contract_value             0\n",
       "total_discount             3\n",
       "mrr                        0\n",
       "change_in_mrr              2\n",
       "pricing_category           0\n",
       "average_usage           1754\n",
       "geographic_region          0\n",
       "billing_location         139\n",
       "customer_status            0\n",
       "contribution_percent       0\n",
       "payment_terms              0\n",
       "payment_method           177\n",
       "employee_count           265\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['deal_id', 'target', 'change_in_mrr', 'employee_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal_type               7\n",
      "deal_start_date      1054\n",
      "industry               10\n",
      "deal_subtype            4\n",
      "business_model         11\n",
      "pricing_category        4\n",
      "geographic_region       9\n",
      "billing_location      482\n",
      "customer_status         8\n",
      "payment_terms           7\n",
      "payment_method          7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "unique_counts = df[categorical_columns].nunique()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Upgrade' 'Auto-Renewal' 'Flat Renewal' 'Downgrade']\n"
     ]
    }
   ],
   "source": [
    "unique_values = df[\"deal_subtype\"].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Encoding Mapping: {'Upgrade': 3, 'Auto-Renewal': 0, 'Flat Renewal': 1, 'Downgrade': 2}\n"
     ]
    }
   ],
   "source": [
    "manual_encoding = {\n",
    "    \"Upgrade\": 3,\n",
    "    \"Auto-Renewal\": 0,\n",
    "    \"Flat Renewal\": 1,\n",
    "    \"Downgrade\": 2\n",
    "}\n",
    "\n",
    "df[\"deal_subtype\"] = df[\"deal_subtype\"].map(manual_encoding)\n",
    "\n",
    "print(\"Manual Encoding Mapping:\", manual_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in object_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    df[col] = label_encoders[col].fit_transform(df[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_deals               int64\n",
       "deal_type                 int32\n",
       "deal_start_date           int32\n",
       "contract_length         float64\n",
       "industry                  int32\n",
       "usage_cycle               int64\n",
       "active_deals              int64\n",
       "deal_subtype              int64\n",
       "business_model            int32\n",
       "account_age               int64\n",
       "contract_value          float64\n",
       "total_discount          float64\n",
       "mrr                     float64\n",
       "pricing_category          int32\n",
       "average_usage           float64\n",
       "geographic_region         int32\n",
       "billing_location          int32\n",
       "customer_status           int32\n",
       "contribution_percent    float64\n",
       "payment_terms             int32\n",
       "payment_method            int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['pricing_category', 'geographic_region', 'customer_status', 'payment_terms', 'usage_cycle'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3513 samples\n",
      "Test set size: 879 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('deal_subtype', axis=1)\n",
    "y = df['deal_subtype']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katerina Boshkoska\\AppData\\Local\\Temp\\ipykernel_27140\\1413820092.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\Katerina Boshkoska\\AppData\\Local\\Temp\\ipykernel_27140\\1413820092.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\Katerina Boshkoska\\AppData\\Local\\Temp\\ipykernel_27140\\1413820092.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\Katerina Boshkoska\\AppData\\Local\\Temp\\ipykernel_27140\\1413820092.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "datasets = {'X_train': X_train, 'X_test': X_test}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "\n",
    "    columns_to_drop = ['deal_id', 'change_in_mrr','employee_count']\n",
    "    data.drop(columns=[col for col in columns_to_drop if col in data.columns], inplace=True)\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    data[['average_usage', 'contribution_percent']] = scaler.fit_transform(data[['average_usage', 'contribution_percent']])\n",
    "\n",
    "    data[['deal_type', 'average_usage', 'contribution_percent']] = imputer.fit_transform(data[['deal_type', 'average_usage', 'contribution_percent']])\n",
    "\n",
    "    for col in ['industry', 'business_model', 'geographic_region', \n",
    "                'billing_location', 'payment_method']:\n",
    "        if col in data.columns:\n",
    "            if not data[col].mode().empty:\n",
    "                data[col] = data[col].fillna(data[col].mode()[0])\n",
    "            else:\n",
    "                data[col] = data[col].fillna('Unknown')\n",
    "  \n",
    "    for col in ['total_discount', 'contract_length', 'employee_count']:\n",
    "        if col in data.columns:\n",
    "            data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "    if 'contract_value' in data.columns:\n",
    "        data['contract_value'] = data['contract_value'].fillna(0)\n",
    "    if 'deal_start_date' in data.columns:\n",
    "        data['deal_start_date'] = data['deal_start_date'].fillna(0)\n",
    "\n",
    "\n",
    "    datasets[name] = data\n",
    "\n",
    "    data.to_csv('Cleaned_datatset.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3513, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3513,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_deals</th>\n",
       "      <th>deal_type</th>\n",
       "      <th>deal_start_date</th>\n",
       "      <th>contract_length</th>\n",
       "      <th>industry</th>\n",
       "      <th>usage_cycle</th>\n",
       "      <th>active_deals</th>\n",
       "      <th>business_model</th>\n",
       "      <th>account_age</th>\n",
       "      <th>contract_value</th>\n",
       "      <th>total_discount</th>\n",
       "      <th>mrr</th>\n",
       "      <th>pricing_category</th>\n",
       "      <th>average_usage</th>\n",
       "      <th>geographic_region</th>\n",
       "      <th>billing_location</th>\n",
       "      <th>customer_status</th>\n",
       "      <th>contribution_percent</th>\n",
       "      <th>payment_terms</th>\n",
       "      <th>payment_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>8.790000e+02</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>8.790000e+02</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>879.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.709898</td>\n",
       "      <td>3.861206</td>\n",
       "      <td>542.215017</td>\n",
       "      <td>12.119454</td>\n",
       "      <td>5.593857</td>\n",
       "      <td>9.516496</td>\n",
       "      <td>0.069397</td>\n",
       "      <td>3.712173</td>\n",
       "      <td>372.369738</td>\n",
       "      <td>2.469225e+04</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>1973.070023</td>\n",
       "      <td>1.119454</td>\n",
       "      <td>0.023407</td>\n",
       "      <td>3.151308</td>\n",
       "      <td>252.790671</td>\n",
       "      <td>1.530148</td>\n",
       "      <td>-1.321658e-15</td>\n",
       "      <td>0.276451</td>\n",
       "      <td>4.096701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.260726</td>\n",
       "      <td>1.729111</td>\n",
       "      <td>294.387253</td>\n",
       "      <td>1.544502</td>\n",
       "      <td>2.721719</td>\n",
       "      <td>4.572811</td>\n",
       "      <td>0.287885</td>\n",
       "      <td>2.749649</td>\n",
       "      <td>352.628743</td>\n",
       "      <td>7.905059e+04</td>\n",
       "      <td>1.165661</td>\n",
       "      <td>6179.068684</td>\n",
       "      <td>0.778745</td>\n",
       "      <td>0.936186</td>\n",
       "      <td>1.837621</td>\n",
       "      <td>139.466538</td>\n",
       "      <td>1.382839</td>\n",
       "      <td>1.000569e+00</td>\n",
       "      <td>0.799931</td>\n",
       "      <td>1.711804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.990000e+02</td>\n",
       "      <td>-18.607800</td>\n",
       "      <td>41.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.630119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.220523e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>295.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>2.298000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.542372</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.654180e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>363.000000</td>\n",
       "      <td>4.800000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.282155</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.643022e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>785.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>398.500000</td>\n",
       "      <td>1.528746e+04</td>\n",
       "      <td>0.370150</td>\n",
       "      <td>1284.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.201969</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>374.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.621344e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1053.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2263.000000</td>\n",
       "      <td>1.345100e+06</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>105425.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.751279</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.259967e+00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_deals   deal_type  deal_start_date  contract_length    industry  \\\n",
       "count   879.000000  879.000000       879.000000       879.000000  879.000000   \n",
       "mean      9.709898    3.861206       542.215017        12.119454    5.593857   \n",
       "std       4.260726    1.729111       294.387253         1.544502    2.721719   \n",
       "min       2.000000    1.000000         0.000000         1.000000    0.000000   \n",
       "25%       6.000000    4.000000       295.500000        12.000000    3.000000   \n",
       "50%      10.000000    4.000000       568.000000        12.000000    5.000000   \n",
       "75%      13.000000    4.000000       785.000000        12.000000    8.000000   \n",
       "max      29.000000    7.000000      1053.000000        36.000000   10.000000   \n",
       "\n",
       "       usage_cycle  active_deals  business_model  account_age  contract_value  \\\n",
       "count   879.000000    879.000000      879.000000   879.000000    8.790000e+02   \n",
       "mean      9.516496      0.069397        3.712173   372.369738    2.469225e+04   \n",
       "std       4.572811      0.287885        2.749649   352.628743    7.905059e+04   \n",
       "min       1.000000      0.000000        0.000000     0.000000    4.990000e+02   \n",
       "25%      12.000000      0.000000        0.000000    62.500000    2.298000e+03   \n",
       "50%      12.000000      0.000000        5.000000   363.000000    4.800000e+03   \n",
       "75%      12.000000      0.000000        6.000000   398.500000    1.528746e+04   \n",
       "max      24.000000      3.000000       11.000000  2263.000000    1.345100e+06   \n",
       "\n",
       "       total_discount            mrr  pricing_category  average_usage  \\\n",
       "count      879.000000     879.000000        879.000000     879.000000   \n",
       "mean         0.007401    1973.070023          1.119454       0.023407   \n",
       "std          1.165661    6179.068684          0.778745       0.936186   \n",
       "min        -18.607800      41.580000          0.000000      -0.630119   \n",
       "25%          0.000000     200.000000          1.000000      -0.542372   \n",
       "50%          0.000000     420.000000          1.000000      -0.282155   \n",
       "75%          0.370150    1284.000000          2.000000       0.201969   \n",
       "max          0.997100  105425.000000          3.000000       7.751279   \n",
       "\n",
       "       geographic_region  billing_location  customer_status  \\\n",
       "count         879.000000        879.000000       879.000000   \n",
       "mean            3.151308        252.790671         1.530148   \n",
       "std             1.837621        139.466538         1.382839   \n",
       "min             0.000000          2.000000         0.000000   \n",
       "25%             2.000000        126.500000         1.000000   \n",
       "50%             3.000000        266.000000         1.000000   \n",
       "75%             5.000000        374.500000         1.000000   \n",
       "max             8.000000        482.000000         6.000000   \n",
       "\n",
       "       contribution_percent  payment_terms  payment_method  \n",
       "count          8.790000e+02     879.000000      879.000000  \n",
       "mean          -1.321658e-15       0.276451        4.096701  \n",
       "std            1.000569e+00       0.799931        1.711804  \n",
       "min           -3.220523e+00       0.000000        0.000000  \n",
       "25%           -5.654180e-01       0.000000        4.000000  \n",
       "50%            2.643022e-01       0.000000        4.000000  \n",
       "75%            7.621344e-01       0.000000        5.500000  \n",
       "max            1.259967e+00       6.000000        7.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_deals             0\n",
       "deal_type               0\n",
       "deal_start_date         0\n",
       "contract_length         0\n",
       "industry                0\n",
       "usage_cycle             0\n",
       "active_deals            0\n",
       "business_model          0\n",
       "account_age             0\n",
       "contract_value          0\n",
       "total_discount          0\n",
       "mrr                     0\n",
       "pricing_category        0\n",
       "average_usage           0\n",
       "geographic_region       0\n",
       "billing_location        0\n",
       "customer_status         0\n",
       "contribution_percent    0\n",
       "payment_terms           0\n",
       "payment_method          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Cleaned_datatset.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замена на категорични податоци со нумерички. Подредени: 'Account Management Tier', 'Stage', 'Opportunity Subtype', 'Pricing Tier' - со колона за секоја категорија 0-не 1-да; Неподредени:'Type', 'Market', 'Business Model', 'Ragion', 'Opportunity Status' - со уникатна бројка за секоја категорија."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal_subtype\n",
      "0    2269\n",
      "3     539\n",
      "2     478\n",
      "1     227\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\katerina boshkoska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\katerina boshkoska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\katerina boshkoska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\katerina boshkoska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\katerina boshkoska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\katerina boshkoska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\katerina boshkoska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: C:\\Users\\Katerina Boshkoska\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal_subtype\n",
      "0    2269\n",
      "3    2269\n",
      "2    2269\n",
      "1    2269\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so smote tehnika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores: [0.78634361 0.78953168 0.7768595  0.76969697 0.80330579]\n",
      "Mean CV Accuracy: 0.7851\n",
      "Standard Deviation of CV Accuracy: 0.0115\n",
      "\n",
      "Accuracy on Test Set: 0.8521\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       566\n",
      "           1       0.47      0.62      0.54        76\n",
      "           2       0.65      0.80      0.71       100\n",
      "           3       0.85      0.68      0.75       137\n",
      "\n",
      "    accuracy                           0.85       879\n",
      "   macro avg       0.73      0.76      0.74       879\n",
      "weighted avg       0.87      0.85      0.86       879\n",
      "\n",
      "Confusion Matrix:\n",
      "[[529  15  21   1]\n",
      " [  5  47  10  14]\n",
      " [  3  15  80   2]\n",
      " [  9  22  13  93]]\n",
      "\n",
      "Best Hyperparameters: {'C': 10, 'max_iter': 10000}\n",
      "Best Cross-Validation Score: 0.8694\n",
      "\n",
      "Accuracy with Best Model: 0.8965\n",
      "Best Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       566\n",
      "           1       0.58      0.68      0.63        76\n",
      "           2       0.75      0.86      0.80       100\n",
      "           3       0.92      0.82      0.87       137\n",
      "\n",
      "    accuracy                           0.90       879\n",
      "   macro avg       0.81      0.83      0.82       879\n",
      "weighted avg       0.91      0.90      0.90       879\n",
      "\n",
      "Best Model Confusion Matrix:\n",
      "[[537  14  14   1]\n",
      " [  5  52  10   9]\n",
      " [  3  11  86   0]\n",
      " [  7  12   5 113]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='saga', max_iter=10000)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train_resampled, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation Accuracy Scores:\", cv_scores)\n",
    "print(f\"Mean CV Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {np.std(cv_scores):.4f}\")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(f'\\nAccuracy on Test Set: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    'max_iter': [5000, 10000, 15000],  # Number of iterations\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(multi_class='multinomial', solver='saga'), param_grid, cv=cv)\n",
    "grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "print(f'\\nBest Hyperparameters: {grid_search.best_params_}')\n",
    "print(f'Best Cross-Validation Score: {grid_search.best_score_:.4f}')\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(f'\\nAccuracy with Best Model: {accuracy_score(y_test, y_pred_best):.4f}')\n",
    "print('Best Model Classification Report:')\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print('Best Model Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bez smote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores: [0.86628734 0.85775249 0.86628734 0.86467236 0.84045584]\n",
      "Mean CV Accuracy: 0.8591\n",
      "Standard Deviation of CV Accuracy: 0.0098\n",
      "\n",
      "Accuracy on Test Set: 0.8532\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       566\n",
      "           1       0.63      0.22      0.33        76\n",
      "           2       0.72      0.73      0.72       100\n",
      "           3       0.64      0.72      0.68       137\n",
      "\n",
      "    accuracy                           0.85       879\n",
      "   macro avg       0.73      0.67      0.67       879\n",
      "weighted avg       0.84      0.85      0.84       879\n",
      "\n",
      "Confusion Matrix:\n",
      "[[561   2   1   2]\n",
      " [  9  17  11  39]\n",
      " [ 12   1  73  14]\n",
      " [ 14   7  17  99]]\n",
      "\n",
      "Best Hyperparameters: {'C': 10, 'max_iter': 5000}\n",
      "Best Cross-Validation Score: 0.8969\n",
      "Cross-validation Accuracy Scores: [0.91322902 0.89046942 0.90184922 0.8974359  0.88176638]\n",
      "Mean CV Accuracy: 0.8969\n",
      "Standard Deviation of CV Accuracy: 0.0106\n",
      "\n",
      "Accuracy with Best Model: 0.8953\n",
      "Best Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       566\n",
      "           1       0.66      0.36      0.46        76\n",
      "           2       0.86      0.85      0.85       100\n",
      "           3       0.80      0.83      0.82       137\n",
      "\n",
      "    accuracy                           0.90       879\n",
      "   macro avg       0.81      0.76      0.77       879\n",
      "weighted avg       0.88      0.90      0.89       879\n",
      "\n",
      "Best Model Confusion Matrix:\n",
      "[[561   4   0   1]\n",
      " [ 13  27   9  27]\n",
      " [ 11   4  85   0]\n",
      " [ 12   6   5 114]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='saga', max_iter=10000)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation Accuracy Scores:\", cv_scores)\n",
    "print(f\"Mean CV Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {np.std(cv_scores):.4f}\")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(f'\\nAccuracy on Test Set: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    'max_iter': [5000, 10000, 15000],  # Number of iterations\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(multi_class='multinomial', solver='saga'), param_grid, cv=cv)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'\\nBest Hyperparameters: {grid_search.best_params_}')\n",
    "print(f'Best Cross-Validation Score: {grid_search.best_score_:.4f}')\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "#cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation Accuracy Scores:\", cv_scores)\n",
    "print(f\"Mean CV Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {np.std(cv_scores):.4f}\")\n",
    "print(f'\\nAccuracy with Best Model: {accuracy_score(y_test, y_pred_best):.4f}')\n",
    "print('Best Model Classification Report:')\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print('Best Model Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OvR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9658703071672355\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       566\n",
      "           1       0.92      0.71      0.80        76\n",
      "           2       1.00      0.98      0.99       100\n",
      "           3       0.98      0.97      0.97       137\n",
      "\n",
      "    accuracy                           0.97       879\n",
      "   macro avg       0.96      0.91      0.94       879\n",
      "weighted avg       0.97      0.97      0.96       879\n",
      "\n",
      "\n",
      "Predicted probabilities (first 5 samples):\n",
      " [[9.64743841e-01 3.30095713e-02 1.00202447e-04 2.14638539e-03]\n",
      " [9.82248594e-01 1.54725575e-02 3.89433273e-05 2.23990470e-03]\n",
      " [1.40719211e-02 2.12936933e-01 1.38156683e-21 7.72991146e-01]\n",
      " [2.90392387e-01 5.80009927e-01 3.29392804e-02 9.66584053e-02]\n",
      " [5.82288482e-02 4.01977672e-02 0.00000000e+00 9.01573385e-01]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model = OneVsRestClassifier(LogisticRegression(solver='liblinear', random_state=42))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "probs = model.predict_proba(X_test)\n",
    "print(\"\\nPredicted probabilities (first 5 samples):\\n\", probs[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najdobar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores: [0.96475771 0.96418733 0.96749311 0.96253444 0.97741047]\n",
      "Mean CV Accuracy: 0.9672766107207437\n",
      "Standard Deviation of CV Accuracy: 0.005312602084918414\n",
      "\n",
      "Test Set Accuracy: 0.9738339021615472\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       566\n",
      "           1       0.83      0.93      0.88        76\n",
      "           2       1.00      0.97      0.98       100\n",
      "           3       1.00      0.97      0.99       137\n",
      "\n",
      "    accuracy                           0.97       879\n",
      "   macro avg       0.95      0.96      0.96       879\n",
      "weighted avg       0.98      0.97      0.97       879\n",
      "\n",
      "\n",
      "AUC Score (Macro Average): 0.983684808213723\n",
      "\n",
      "Confusion Matrix:\n",
      " [[555  11   0   0]\n",
      " [  5  71   0   0]\n",
      " [  2   1  97   0]\n",
      " [  1   3   0 133]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "model = OneVsRestClassifier(LogisticRegression(solver='liblinear', random_state=42))\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation of CV Accuracy:\", np.std(cv_scores))\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)  \n",
    "\n",
    "print(\"\\nTest Set Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr', average='macro')\n",
    "print(\"\\nAUC Score (Macro Average):\", auc_score)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores: [0.96870555 0.9715505  0.97297297 0.97435897 0.97578348]\n",
      "Mean CV Accuracy: 0.9726742937269253\n",
      "Standard Deviation of CV Accuracy: 0.002433443392444015\n",
      "\n",
      "Test Set Accuracy: 0.9658703071672355\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       566\n",
      "           1       0.92      0.71      0.80        76\n",
      "           2       1.00      0.98      0.99       100\n",
      "           3       0.98      0.97      0.97       137\n",
      "\n",
      "    accuracy                           0.97       879\n",
      "   macro avg       0.96      0.91      0.94       879\n",
      "weighted avg       0.97      0.97      0.96       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model = OneVsRestClassifier(LogisticRegression(solver='liblinear', random_state=42))\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold  CV\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation of CV Accuracy:\", np.std(cv_scores))\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Set Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88       566\n",
      "           1       0.27      0.41      0.32        76\n",
      "           2       0.24      0.34      0.28       100\n",
      "           3       0.42      0.39      0.41       137\n",
      "\n",
      "    accuracy                           0.67       879\n",
      "   macro avg       0.47      0.49      0.47       879\n",
      "weighted avg       0.72      0.67      0.69       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "knn.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best Cross-Validation Score: 0.888389582650696\n",
      "\n",
      "Test Set Accuracy: 0.6905574516496018\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       566\n",
      "           1       0.31      0.34      0.33        76\n",
      "           2       0.30      0.35      0.32       100\n",
      "           3       0.47      0.49      0.48       137\n",
      "\n",
      "    accuracy                           0.69       879\n",
      "   macro avg       0.49      0.51      0.50       879\n",
      "weighted avg       0.71      0.69      0.70       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9],           # Different values for k\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # Weighting strategies\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"], # Distance metrics\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",   \n",
    "    cv=5, \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "best_knn = grid_search.best_estimator_ \n",
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTest Set Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.726962457337884\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       566\n",
      "           1       0.31      0.20      0.24        76\n",
      "           2       0.38      0.29      0.33       100\n",
      "           3       0.52      0.33      0.40       137\n",
      "\n",
      "    accuracy                           0.73       879\n",
      "   macro avg       0.51      0.45      0.47       879\n",
      "weighted avg       0.68      0.73      0.70       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "Best Cross-Validation Score: 0.744663692032113\n",
      "\n",
      "AUC Score (Macro Average): 0.8401937603203535\n",
      "\n",
      "Test Set Accuracy: 0.7724687144482366\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       566\n",
      "           1       0.50      0.30      0.38        76\n",
      "           2       0.43      0.36      0.39       100\n",
      "           3       0.58      0.52      0.55       137\n",
      "\n",
      "    accuracy                           0.77       879\n",
      "   macro avg       0.60      0.54      0.56       879\n",
      "weighted avg       0.75      0.77      0.76       879\n",
      "\n",
      "Confusion matrix:\n",
      " [[549   3   9   5]\n",
      " [ 20  23  15  18]\n",
      " [ 26  10  36  28]\n",
      " [ 32  10  24  71]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"], \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\", \n",
    "    cv=5, \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "best_knn = grid_search.best_estimator_ \n",
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])  \n",
    "y_pred_proba = best_knn.predict_proba(X_test_scaled)\n",
    "\n",
    "auc_score = roc_auc_score(y_test_binarized, y_pred_proba, average=\"macro\")\n",
    "print(\"\\nAUC Score (Macro Average):\", auc_score)\n",
    "\n",
    "print(\"\\nTest Set Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Accuracy: 0.4990\n",
      "Test Accuracy: 0.7201\n",
      "Confusion Matrix:\n",
      "[[545  10   7   4]\n",
      " [ 30  24  15   7]\n",
      " [ 41  14  36   9]\n",
      " [ 37  37  35  28]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       566\n",
      "           1       0.28      0.32      0.30        76\n",
      "           2       0.39      0.36      0.37       100\n",
      "           3       0.58      0.20      0.30       137\n",
      "\n",
      "    accuracy                           0.72       879\n",
      "   macro avg       0.52      0.46      0.47       879\n",
      "weighted avg       0.70      0.72      0.69       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "cv_scores = cross_val_score(nb_model, X_train_scaled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Mean Cross-Validation Accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "nb_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najdobar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Accuracy: 0.6840\n",
      "Test Accuracy: 0.6928\n",
      "Confusion Matrix:\n",
      "[[546  11   7   2]\n",
      " [ 48  14   9   5]\n",
      " [ 64   7  18  11]\n",
      " [ 74  16  16  31]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84       566\n",
      "           1       0.29      0.18      0.23        76\n",
      "           2       0.36      0.18      0.24       100\n",
      "           3       0.63      0.23      0.33       137\n",
      "\n",
      "    accuracy                           0.69       879\n",
      "   macro avg       0.51      0.39      0.41       879\n",
      "weighted avg       0.65      0.69      0.64       879\n",
      "\n",
      "AUC Score (OvR): 0.8450\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "cv_scores = cross_val_score(nb_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Mean Cross-Validation Accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_scaled)\n",
    "y_proba = nb_model.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8396\n",
      "Confusion Matrix:\n",
      "[[530  12  12  12]\n",
      " [  7  38  12  19]\n",
      " [  8   8  73  11]\n",
      " [  8  19  13  97]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       566\n",
      "           1       0.49      0.50      0.50        76\n",
      "           2       0.66      0.73      0.70       100\n",
      "           3       0.70      0.71      0.70       137\n",
      "\n",
      "    accuracy                           0.84       879\n",
      "   macro avg       0.70      0.72      0.71       879\n",
      "weighted avg       0.84      0.84      0.84       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GRID SEARCH (PRUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8350\n",
      "Confusion Matrix:\n",
      "[[531  10  12  13]\n",
      " [  6  35  10  25]\n",
      " [  7  13  71   9]\n",
      " [  7  20  13  97]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       566\n",
      "           1       0.45      0.46      0.45        76\n",
      "           2       0.67      0.71      0.69       100\n",
      "           3       0.67      0.71      0.69       137\n",
      "\n",
      "    accuracy                           0.84       879\n",
      "   macro avg       0.69      0.70      0.70       879\n",
      "weighted avg       0.84      0.84      0.84       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8248\n",
      "Confusion Matrix:\n",
      "[[542   6  12   6]\n",
      " [  8  27  15  26]\n",
      " [  8  10  70  12]\n",
      " [ 12  24  15  86]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       566\n",
      "           1       0.40      0.36      0.38        76\n",
      "           2       0.62      0.70      0.66       100\n",
      "           3       0.66      0.63      0.64       137\n",
      "\n",
      "    accuracy                           0.82       879\n",
      "   macro avg       0.66      0.66      0.66       879\n",
      "weighted avg       0.82      0.82      0.82       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*najdobar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy (5 folds): [0.84495021 0.84495021 0.83926031 0.84615385 0.85185185]\n",
      "Mean CV Accuracy: 0.8454\n",
      "Standard Deviation of CV Accuracy: 0.0040\n",
      "Test Set Accuracy: 0.8726\n",
      "AUC Score: 0.8586\n",
      "Confusion Matrix:\n",
      "[[544   8   7   7]\n",
      " [  5  41  12  18]\n",
      " [  7   7  83   3]\n",
      " [  9  20   9  99]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       566\n",
      "           1       0.54      0.54      0.54        76\n",
      "           2       0.75      0.83      0.79       100\n",
      "           3       0.78      0.72      0.75       137\n",
      "\n",
      "    accuracy                           0.87       879\n",
      "   macro avg       0.76      0.76      0.76       879\n",
      "weighted avg       0.87      0.87      0.87       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "important_features = ['account_age', 'mrr', 'contract_value', 'deal_type', \n",
    "                      'average_usage', 'contract_length', 'contribution_percent', \n",
    "                      'total_discount', 'deal_start_date', 'billing_location']\n",
    "\n",
    "X_train_important = X_train[important_features]\n",
    "X_test_important = X_test[important_features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_important)\n",
    "X_test_scaled = scaler.transform(X_test_important)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(dt, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, dt.predict_proba(X_test_scaled), multi_class='ovr')\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Cross-Validation Accuracy (5 folds): {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {mean_cv_score:.4f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {std_cv_score:.4f}\")\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy (5 folds): [0.85490754 0.83357041 0.85206259 0.83333333 0.83190883]\n",
      "Mean CV Accuracy: 0.8412\n",
      "Standard Deviation of CV Accuracy: 0.0101\n",
      "Test Set Accuracy: 0.8623\n",
      "Confusion Matrix:\n",
      "[[545   4  10   7]\n",
      " [  6  34  17  19]\n",
      " [  7   5  82   6]\n",
      " [  9  19  12  97]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       566\n",
      "           1       0.55      0.45      0.49        76\n",
      "           2       0.68      0.82      0.74       100\n",
      "           3       0.75      0.71      0.73       137\n",
      "\n",
      "    accuracy                           0.86       879\n",
      "   macro avg       0.73      0.73      0.73       879\n",
      "weighted avg       0.86      0.86      0.86       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(dt, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Cross-Validation Accuracy (5 folds): {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {mean_cv_score:.4f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {std_cv_score:.4f}\")\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAGGING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8885\n",
      "Confusion Matrix:\n",
      "[[553   5   3   5]\n",
      " [  6  41   7  22]\n",
      " [  8   5  83   4]\n",
      " [  6  18   9 104]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       566\n",
      "           1       0.59      0.54      0.57        76\n",
      "           2       0.81      0.83      0.82       100\n",
      "           3       0.77      0.76      0.76       137\n",
      "\n",
      "    accuracy                           0.89       879\n",
      "   macro avg       0.79      0.78      0.78       879\n",
      "weighted avg       0.89      0.89      0.89       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(random_state=42), n_estimators=50, random_state=42)\n",
    "\n",
    "bagging.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = bagging.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GRID SEARCH AND CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'estimator__max_depth': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'max_samples': 1.0, 'n_estimators': 100}\n",
      "Cross-Validation Scores (5 folds): [0.96992318]\n",
      "Mean Cross-Validation Accuracy: 0.9699\n",
      "Test Set Accuracy: 0.8885\n",
      "Confusion Matrix:\n",
      "[[553   4   2   7]\n",
      " [  6  42   9  19]\n",
      " [  6   7  82   5]\n",
      " [  7  16  10 104]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       566\n",
      "           1       0.61      0.55      0.58        76\n",
      "           2       0.80      0.82      0.81       100\n",
      "           3       0.77      0.76      0.76       137\n",
      "\n",
      "    accuracy                           0.89       879\n",
      "   macro avg       0.79      0.78      0.78       879\n",
      "weighted avg       0.89      0.89      0.89       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(estimator=tree, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100],  # Number of base estimators\n",
    "    'max_samples': [1.0],    # Fraction of samples used for each base estimator\n",
    "    'estimator__max_depth': [None],  # Max depth for base estimator (DecisionTree)\n",
    "    'estimator__min_samples_split': [2],  # Minimum samples to split a node in DecisionTree\n",
    "    'estimator__min_samples_leaf': [1]  # Minimum samples per leaf in DecisionTree\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "print(\"Cross-Validation Scores (5 folds):\", grid_search.cv_results_['mean_test_score'])\n",
    "print(f\"Mean Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najdobar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy (5 folds): [0.87908962 0.88051209 0.88193457 0.88319088 0.87891738]\n",
      "Mean CV Accuracy: 0.8807\n",
      "Standard Deviation of CV Accuracy: 0.0016\n",
      "Test Set Accuracy: 0.8976\n",
      "AUC Score: 0.9729\n",
      "Confusion Matrix:\n",
      "[[563   0   2   1]\n",
      " [  9  33   9  25]\n",
      " [  9   2  85   4]\n",
      " [  8  10  11 108]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       566\n",
      "           1       0.73      0.43      0.55        76\n",
      "           2       0.79      0.85      0.82       100\n",
      "           3       0.78      0.79      0.79       137\n",
      "\n",
      "    accuracy                           0.90       879\n",
      "   macro avg       0.82      0.77      0.78       879\n",
      "weighted avg       0.89      0.90      0.89       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(random_state=42), n_estimators=50, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(bagging, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "bagging.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = bagging.predict(X_test_scaled)\n",
    "y_prob = bagging.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f\"Cross-Validation Accuracy (5 folds): {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {mean_cv_score:.4f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {std_cv_score:.4f}\")\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'estimator__max_depth': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'max_samples': 1.0, 'n_estimators': 100}\n",
      "Cross-Validation Scores (5 folds): [0.88215138]\n",
      "Mean Cross-Validation Accuracy: 0.8822\n",
      "Test Set Accuracy: 0.8965\n",
      "Confusion Matrix:\n",
      "[[561   0   3   2]\n",
      " [  8  31  11  26]\n",
      " [  9   2  85   4]\n",
      " [  9   8   9 111]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       566\n",
      "           1       0.76      0.41      0.53        76\n",
      "           2       0.79      0.85      0.82       100\n",
      "           3       0.78      0.81      0.79       137\n",
      "\n",
      "    accuracy                           0.90       879\n",
      "   macro avg       0.82      0.76      0.78       879\n",
      "weighted avg       0.89      0.90      0.89       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(estimator=tree, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100],  # Number of base estimators\n",
    "    'max_samples': [1.0],    # Fraction of samples used for each base estimator\n",
    "    'estimator__max_depth': [None],  # Max depth for base estimator (DecisionTree)\n",
    "    'estimator__min_samples_split': [2],  # Minimum samples to split a node in DecisionTree\n",
    "    'estimator__min_samples_leaf': [1]  # Minimum samples per leaf in DecisionTree\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "print(\"Cross-Validation Scores (5 folds):\", grid_search.cv_results_['mean_test_score'])\n",
    "print(f\"Mean Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8555\n",
      "Confusion Matrix:\n",
      "[[558   2   1   5]\n",
      " [  7  30  11  28]\n",
      " [ 11   7  66  16]\n",
      " [  8  17  14  98]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       566\n",
      "           1       0.54      0.39      0.45        76\n",
      "           2       0.72      0.66      0.69       100\n",
      "           3       0.67      0.72      0.69       137\n",
      "\n",
      "    accuracy                           0.86       879\n",
      "   macro avg       0.72      0.69      0.70       879\n",
      "weighted avg       0.85      0.86      0.85       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GRID SEARCH AND CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Cross-Validation Scores (5 folds): [0.96794147]\n",
      "Mean Cross-Validation Accuracy: 0.9679\n",
      "Test Set Accuracy: 0.8589\n",
      "Confusion Matrix:\n",
      "[[557   3   1   5]\n",
      " [  7  30  15  24]\n",
      " [ 11   7  70  12]\n",
      " [ 10  16  13  98]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       566\n",
      "           1       0.54      0.39      0.45        76\n",
      "           2       0.71      0.70      0.70       100\n",
      "           3       0.71      0.72      0.71       137\n",
      "\n",
      "    accuracy                           0.86       879\n",
      "   macro avg       0.72      0.70      0.71       879\n",
      "weighted avg       0.85      0.86      0.85       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200],  # Number of trees\n",
    "    'max_depth': [None],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1],  # Minimum samples required at each leaf node\n",
    "    'bootstrap': [False]  # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "print(\"Cross-Validation Scores (5 folds):\", grid_search.cv_results_['mean_test_score'])\n",
    "print(f\"Mean Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8589\n",
      "Confusion Matrix:\n",
      "[[563   0   1   2]\n",
      " [ 10  22  13  31]\n",
      " [ 13   1  67  19]\n",
      " [ 12   6  16 103]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       566\n",
      "           1       0.76      0.29      0.42        76\n",
      "           2       0.69      0.67      0.68       100\n",
      "           3       0.66      0.75      0.71       137\n",
      "\n",
      "    accuracy                           0.86       879\n",
      "   macro avg       0.76      0.68      0.69       879\n",
      "weighted avg       0.85      0.86      0.85       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najdobar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Cross-Validation Scores (5 folds): [0.85539507]\n",
      "Mean Cross-Validation Accuracy: 0.8554\n",
      "Test Set Accuracy: 0.8646\n",
      "AUC Score: 0.9701\n",
      "Confusion Matrix:\n",
      "[[562   0   2   2]\n",
      " [  9  26  11  30]\n",
      " [ 12   3  68  17]\n",
      " [ 11   6  16 104]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       566\n",
      "           1       0.74      0.34      0.47        76\n",
      "           2       0.70      0.68      0.69       100\n",
      "           3       0.68      0.76      0.72       137\n",
      "\n",
      "    accuracy                           0.86       879\n",
      "   macro avg       0.77      0.69      0.71       879\n",
      "weighted avg       0.86      0.86      0.85       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200],  # Number of trees\n",
    "    'max_depth': [None],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1],  # Minimum samples required at each leaf node\n",
    "    'bootstrap': [False]  # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "print(\"Cross-Validation Scores (5 folds):\", grid_search.cv_results_['mean_test_score'])\n",
    "print(f\"Mean Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_prob = best_rf.predict_proba(X_test_scaled)\n",
    "auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        ADABOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7691\n",
      "Confusion Matrix:\n",
      "[[541  15   4   6]\n",
      " [  9  22  21  24]\n",
      " [ 12  16  50  22]\n",
      " [  6  33  35  63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       566\n",
      "           1       0.26      0.29      0.27        76\n",
      "           2       0.45      0.50      0.48       100\n",
      "           3       0.55      0.46      0.50       137\n",
      "\n",
      "    accuracy                           0.77       879\n",
      "   macro avg       0.55      0.55      0.55       879\n",
      "weighted avg       0.77      0.77      0.77       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "adaboost.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = adaboost.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FEATURE IMPORTANCE - REDUCED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "                 Feature  Importance\n",
      "8            account_age    0.508718\n",
      "9         contract_value    0.153175\n",
      "1              deal_type    0.136607\n",
      "11                   mrr    0.109865\n",
      "5            usage_cycle    0.055390\n",
      "4               industry    0.018967\n",
      "3        contract_length    0.017278\n",
      "0            total_deals    0.000000\n",
      "14     geographic_region    0.000000\n",
      "18         payment_terms    0.000000\n",
      "17  contribution_percent    0.000000\n",
      "16       customer_status    0.000000\n",
      "15      billing_location    0.000000\n",
      "10        total_discount    0.000000\n",
      "13         average_usage    0.000000\n",
      "12      pricing_category    0.000000\n",
      "7         business_model    0.000000\n",
      "6           active_deals    0.000000\n",
      "2        deal_start_date    0.000000\n",
      "19        payment_method    0.000000\n",
      "\n",
      "Dropped Features:\n",
      "{'contribution_percent', 'business_model', 'customer_status', 'average_usage', 'pricing_category', 'payment_terms', 'total_discount', 'active_deals', 'billing_location', 'geographic_region', 'payment_method', 'total_deals', 'deal_start_date'}\n",
      "\n",
      "Accuracy after feature selection: 0.7736\n",
      "Confusion Matrix:\n",
      "[[545  14   3   4]\n",
      " [  9  25  12  30]\n",
      " [ 15  21  45  19]\n",
      " [ 12  38  22  65]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       566\n",
      "           1       0.26      0.33      0.29        76\n",
      "           2       0.55      0.45      0.49       100\n",
      "           3       0.55      0.47      0.51       137\n",
      "\n",
      "    accuracy                           0.77       879\n",
      "   macro avg       0.57      0.55      0.56       879\n",
      "weighted avg       0.77      0.77      0.77       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "adaboost = AdaBoostClassifier(algorithm='SAMME', n_estimators=50, random_state=42)\n",
    "\n",
    "adaboost.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "feature_importances = adaboost.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_resampled.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "threshold = 0.01\n",
    "important_features = feature_importance_df[feature_importance_df['Importance'] >= threshold]['Feature']\n",
    "\n",
    "dropped_features = set(X_train_resampled.columns) - set(important_features)\n",
    "\n",
    "print(\"\\nDropped Features:\")\n",
    "print(dropped_features)\n",
    "\n",
    "X_train_filtered = X_train_resampled[important_features]\n",
    "X_test_filtered = X_test[important_features]\n",
    "\n",
    "adaboost.fit(X_train_filtered, y_train_resampled)\n",
    "\n",
    "y_pred = adaboost.predict(X_test_filtered)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy after feature selection: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters from GridSearchCV: {'learning_rate': 1.0, 'n_estimators': 200}\n",
      "\n",
      "Cross-validation scores: [0.71971366 0.73939394 0.74710744 0.7399449  0.72341598]\n",
      "Mean cross-validation accuracy: 0.7339\n",
      "Standard deviation of cross-validation accuracy: 0.0105\n",
      "\n",
      "Test Set Accuracy: 0.8191\n",
      "Confusion Matrix:\n",
      "[[547  16   1   2]\n",
      " [  7  39  10  20]\n",
      " [  9  24  62   5]\n",
      " [  9  43  13  72]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       566\n",
      "           1       0.32      0.51      0.39        76\n",
      "           2       0.72      0.62      0.67       100\n",
      "           3       0.73      0.53      0.61       137\n",
      "\n",
      "    accuracy                           0.82       879\n",
      "   macro avg       0.68      0.66      0.66       879\n",
      "weighted avg       0.84      0.82      0.82       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ada_boost = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200],  # Number of boosting rounds\n",
    "    'learning_rate': [1.0],  # Learning rate\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=ada_boost, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_filtered, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest parameters from GridSearchCV:\", best_params)\n",
    "\n",
    "cv_scores = cross_val_score(best_model, X_train_filtered, y_train_resampled, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"\\nCross-validation scores:\", cv_scores)\n",
    "print(f\"Mean cross-validation accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard deviation of cross-validation accuracy: {cv_scores.std():.4f}\")\n",
    "\n",
    "y_pred = best_model.predict(X_test_filtered)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nTest Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najdobar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.80938834 0.80085349 0.80938834 0.78205128 0.78917379]\n",
      "Mean Cross-Validation Accuracy: 0.7982\n",
      "Standard Deviation of Cross-Validation Accuracy: 0.0110\n",
      "Test Set Accuracy: 0.8066\n",
      "Confusion Matrix:\n",
      "[[557   3   2   4]\n",
      " [  6  16  15  39]\n",
      " [ 13   9  40  38]\n",
      " [ 10  10  21  96]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       566\n",
      "           1       0.42      0.21      0.28        76\n",
      "           2       0.51      0.40      0.45       100\n",
      "           3       0.54      0.70      0.61       137\n",
      "\n",
      "    accuracy                           0.81       879\n",
      "   macro avg       0.61      0.57      0.58       879\n",
      "weighted avg       0.79      0.81      0.79       879\n",
      "\n",
      "AUC Score (OvR): 0.8894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(adaboost, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation of Cross-Validation Accuracy: {cv_scores.std():.4f}\")\n",
    "\n",
    "adaboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = adaboost.predict(X_test_scaled)\n",
    "y_proba = adaboost.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Cross-Validation Scores (5 folds): [0.77113429 0.7705649  0.78223    0.7904909  0.79789303 0.80102289\n",
      " 0.79817105 0.79390119 0.79020113]\n",
      "Mean Cross-Validation Accuracy: 0.8010\n",
      "Test Set Accuracy: 0.7986\n",
      "Confusion Matrix:\n",
      "[[562   0   0   4]\n",
      " [  9   3  20  44]\n",
      " [ 17   0  37  46]\n",
      " [ 13   0  24 100]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       566\n",
      "           1       1.00      0.04      0.08        76\n",
      "           2       0.46      0.37      0.41       100\n",
      "           3       0.52      0.73      0.60       137\n",
      "\n",
      "    accuracy                           0.80       879\n",
      "   macro avg       0.73      0.53      0.51       879\n",
      "weighted avg       0.82      0.80      0.77       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of weak learners (decision trees)\n",
    "    'learning_rate': [0.01, 0.1, 1],  # How much each weak learner impacts the final prediction\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=adaboost, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_adaboost = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "print(\"Cross-Validation Scores (5 folds):\", grid_search.cv_results_['mean_test_score'])\n",
    "print(f\"Mean Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_adaboost.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "                 Feature  Importance\n",
      "8            account_age    0.570911\n",
      "9         contract_value    0.150036\n",
      "1              deal_type    0.118189\n",
      "11                   mrr    0.077186\n",
      "5            usage_cycle    0.035473\n",
      "10        total_discount    0.025117\n",
      "4               industry    0.023087\n",
      "13         average_usage    0.000000\n",
      "18         payment_terms    0.000000\n",
      "17  contribution_percent    0.000000\n",
      "16       customer_status    0.000000\n",
      "15      billing_location    0.000000\n",
      "14     geographic_region    0.000000\n",
      "0            total_deals    0.000000\n",
      "12      pricing_category    0.000000\n",
      "7         business_model    0.000000\n",
      "6           active_deals    0.000000\n",
      "3        contract_length    0.000000\n",
      "2        deal_start_date    0.000000\n",
      "19        payment_method    0.000000\n",
      "\n",
      "Dropped Features:\n",
      "{'contribution_percent', 'contract_length', 'business_model', 'customer_status', 'average_usage', 'pricing_category', 'payment_terms', 'active_deals', 'billing_location', 'geographic_region', 'payment_method', 'total_deals', 'deal_start_date'}\n",
      "\n",
      "Accuracy after feature selection: 0.7873\n",
      "Confusion Matrix:\n",
      "[[564   0   0   2]\n",
      " [ 11   5  12  48]\n",
      " [ 19   5  32  44]\n",
      " [ 17  10  19  91]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       566\n",
      "           1       0.25      0.07      0.10        76\n",
      "           2       0.51      0.32      0.39       100\n",
      "           3       0.49      0.66      0.57       137\n",
      "\n",
      "    accuracy                           0.79       879\n",
      "   macro avg       0.54      0.51      0.51       879\n",
      "weighted avg       0.75      0.79      0.76       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "adaboost = AdaBoostClassifier(algorithm='SAMME', n_estimators=50, random_state=42)\n",
    "adaboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "feature_importances = adaboost.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "threshold = 0.01\n",
    "important_features = feature_importance_df[feature_importance_df['Importance'] >= threshold]['Feature']\n",
    "\n",
    "dropped_features = set(X_train.columns) - set(important_features)\n",
    "\n",
    "print(\"\\nDropped Features:\")\n",
    "print(dropped_features)\n",
    "\n",
    "X_train_filtered = X_train[important_features]\n",
    "X_test_filtered = X_test[important_features]\n",
    "\n",
    "adaboost.fit(X_train_filtered, y_train)\n",
    "\n",
    "y_pred = adaboost.predict(X_test_filtered)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy after feature selection: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8965\n",
      "Confusion Matrix:\n",
      "[[553   4   3   6]\n",
      " [  6  43   8  19]\n",
      " [  5   6  85   4]\n",
      " [  5  20   5 107]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       566\n",
      "           1       0.59      0.57      0.58        76\n",
      "           2       0.84      0.85      0.85       100\n",
      "           3       0.79      0.78      0.78       137\n",
      "\n",
      "    accuracy                           0.90       879\n",
      "   macro avg       0.80      0.79      0.80       879\n",
      "weighted avg       0.90      0.90      0.90       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "gradient_boosting.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = gradient_boosting.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV and Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.5, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross-Validation Scores (5 folds): [0.68830312 0.68158184 0.72653469 0.71551698 0.79198371 0.78911864\n",
      " 0.79165283 0.78239839 0.83925177 0.83506377 0.90602032 0.90282551\n",
      " 0.88288291 0.85743243 0.92144567 0.90866549 0.9557114  0.9509742\n",
      " 0.87638184 0.87572105 0.93224409 0.92739524 0.96210271 0.9612208\n",
      " 0.9518555  0.95416876 0.97521292 0.97311932 0.980281   0.97939946\n",
      " 0.97576322 0.97422131 0.98237388 0.97917889 0.98490777 0.98270415\n",
      " 0.96298322 0.96397513 0.97389152 0.97488283 0.97785767 0.98017093\n",
      " 0.97752655 0.97884898 0.98237418 0.98281508 0.98479788 0.9850182\n",
      " 0.98259414 0.98325512 0.98633985 0.98567881 0.98722115 0.98645004]\n",
      "Mean Cross-Validation Accuracy: 0.9872\n",
      "Test Set Accuracy: 0.9238\n",
      "Confusion Matrix:\n",
      "[[561   3   0   2]\n",
      " [  6  42   5  23]\n",
      " [  4   3  91   2]\n",
      " [  4  13   2 118]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       566\n",
      "           1       0.69      0.55      0.61        76\n",
      "           2       0.93      0.91      0.92       100\n",
      "           3       0.81      0.86      0.84       137\n",
      "\n",
      "    accuracy                           0.92       879\n",
      "   macro avg       0.85      0.83      0.84       879\n",
      "weighted avg       0.92      0.92      0.92       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of boosting trees\n",
    "    'learning_rate': [0.01, 0.1, 0.5],  # Contribution of each tree\n",
    "    'max_depth': [3, 5, 7],  # Maximum depth of the individual trees\n",
    "    'subsample': [0.8, 1.0]  # Fraction of samples used for fitting trees\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gradient_boosting, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_gradient_boosting = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "print(\"Cross-Validation Scores (5 folds):\", grid_search.cv_results_['mean_test_score'])\n",
    "print(f\"Mean Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_gradient_boosting.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najdobar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross-Validation Scores (5 folds): [0.69228216 0.69768919 0.8277792  0.82379383 0.84798685 0.84684806\n",
      " 0.74779192 0.74779111 0.85880455 0.84827256 0.87929995 0.87503333\n",
      " 0.78934886 0.79390443 0.87076388 0.86393033 0.89182867 0.88699063\n",
      " 0.88186567 0.88158118 0.89780469 0.89751979 0.90549051 0.90890729\n",
      " 0.89723853 0.89979858 0.89979777 0.90378435 0.90349824 0.90549254\n",
      " 0.89752262 0.89894753 0.90179086 0.90890931 0.90350026 0.90919381\n",
      " 0.89808553 0.90179329 0.89837408 0.90463946 0.90179086 0.90919502\n",
      " 0.89553116 0.90264475 0.89980183 0.90720072 0.90350107 0.91175791\n",
      " 0.89154255 0.90520845 0.89552873 0.90720072 0.89467362 0.90691582]\n",
      "Mean Cross-Validation Accuracy: 0.9118\n",
      "Test Set Accuracy: 0.9124\n",
      "Confusion Matrix:\n",
      "[[564   0   0   2]\n",
      " [  9  35   9  23]\n",
      " [  5   3  89   3]\n",
      " [  8  12   3 114]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       566\n",
      "           1       0.70      0.46      0.56        76\n",
      "           2       0.88      0.89      0.89       100\n",
      "           3       0.80      0.83      0.82       137\n",
      "\n",
      "    accuracy                           0.91       879\n",
      "   macro avg       0.84      0.79      0.81       879\n",
      "weighted avg       0.91      0.91      0.91       879\n",
      "\n",
      "AUC Score (OvR): 0.9742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of boosting stages (trees)\n",
    "    'learning_rate': [0.01, 0.1, 0.5],  # Contribution of each tree\n",
    "    'max_depth': [3, 5, 7],  # Maximum depth of the individual trees\n",
    "    'subsample': [0.8, 1.0]  # Fraction of samples used for fitting trees\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gradient_boosting, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_gradient_boosting = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "print(\"Cross-Validation Scores (5 folds):\", grid_search.cv_results_['mean_test_score'])\n",
    "print(f\"Mean Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_gradient_boosting.predict(X_test_scaled)\n",
    "y_proba = best_gradient_boosting.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      XGBOOST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9158\n",
      "Confusion Matrix:\n",
      "[[561   2   1   2]\n",
      " [  6  43   3  24]\n",
      " [  3   5  89   3]\n",
      " [  7  13   5 112]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       566\n",
      "           1       0.68      0.57      0.62        76\n",
      "           2       0.91      0.89      0.90       100\n",
      "           3       0.79      0.82      0.81       137\n",
      "\n",
      "    accuracy                           0.92       879\n",
      "   macro avg       0.84      0.82      0.83       879\n",
      "weighted avg       0.91      0.92      0.91       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "xgboost = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "xgboost.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = xgboost.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID SEARCH AND CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najdobar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katerina Boshkoska\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Mean Cross-Validation Score: 0.9807\n",
      "Best parameters: {'subsample': 0.9, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 7, 'learning_rate': 0.3, 'lambda': 1, 'gamma': 0.1, 'colsample_bytree': 0.8, 'alpha': 0.5}\n",
      "Best cross-validation accuracy: 0.9807\n",
      "Accuracy: 0.9124\n",
      "Confusion Matrix:\n",
      "[[560   3   2   1]\n",
      " [  8  44   3  21]\n",
      " [  3   5  90   2]\n",
      " [  8  15   6 108]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       566\n",
      "           1       0.66      0.58      0.62        76\n",
      "           2       0.89      0.90      0.90       100\n",
      "           3       0.82      0.79      0.80       137\n",
      "\n",
      "    accuracy                           0.91       879\n",
      "   macro avg       0.83      0.81      0.82       879\n",
      "weighted avg       0.91      0.91      0.91       879\n",
      "\n",
      "AUC Score (OvR): 0.9733\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [0.3],\n",
    "    'n_estimators': [200],\n",
    "    'subsample': [0.9],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'min_child_weight': [3],\n",
    "    'gamma': [0.1],\n",
    "    'lambda': [1],\n",
    "    'alpha': [0.5]\n",
    "}\n",
    "\n",
    "xgboost_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train_resampled)), eval_metric='merror')\n",
    "\n",
    "randomized_search = RandomizedSearchCV(estimator=xgboost_model, param_distributions=param_dist,\n",
    "                                       n_iter=10, scoring='accuracy', cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "randomized_search.fit(X_train_resampled, y_train_resampled)\n",
    "cv_scores = randomized_search.cv_results_['mean_test_score']\n",
    "mean_cv_score = cv_scores.mean()\n",
    "print(f\"Mean Cross-Validation Score: {mean_cv_score:.4f}\")\n",
    "best_params = randomized_search.best_params_\n",
    "best_score = randomized_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best cross-validation accuracy: {best_score:.4f}\")\n",
    "\n",
    "y_pred = randomized_search.best_estimator_.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katerina Boshkoska\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'subsample': 0.9, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 7, 'learning_rate': 0.3, 'lambda': 1, 'gamma': 0.1, 'colsample_bytree': 0.8, 'alpha': 0.5}\n",
      "Best cross-validation accuracy: 0.8989\n",
      "Accuracy: 0.9010\n",
      "Confusion Matrix:\n",
      "[[561   1   1   3]\n",
      " [  7  35  12  22]\n",
      " [  8   4  84   4]\n",
      " [  8  10   7 112]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       566\n",
      "           1       0.70      0.46      0.56        76\n",
      "           2       0.81      0.84      0.82       100\n",
      "           3       0.79      0.82      0.81       137\n",
      "\n",
      "    accuracy                           0.90       879\n",
      "   macro avg       0.82      0.78      0.79       879\n",
      "weighted avg       0.89      0.90      0.90       879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [0.3],\n",
    "    'n_estimators': [200],\n",
    "    'subsample': [0.9],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'min_child_weight': [3],\n",
    "    'gamma': [0.1],\n",
    "    'lambda': [1],\n",
    "    'alpha': [0.5]\n",
    "}\n",
    "\n",
    "xgboost_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)), eval_metric='merror')\n",
    "\n",
    "randomized_search = RandomizedSearchCV(estimator=xgboost_model, param_distributions=param_dist,\n",
    "                                       n_iter=10, scoring='accuracy', cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = randomized_search.best_params_\n",
    "best_score = randomized_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best cross-validation accuracy: {best_score:.4f}\")\n",
    "\n",
    "y_pred = randomized_search.best_estimator_.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB, knn and ada without smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Accuracy: 0.7770\n",
      "Confusion Matrix:\n",
      "[[559   0   4   3]\n",
      " [ 12   6  17  41]\n",
      " [ 20   2  36  42]\n",
      " [ 21   3  31  82]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       566\n",
      "           1       0.55      0.08      0.14        76\n",
      "           2       0.41      0.36      0.38       100\n",
      "           3       0.49      0.60      0.54       137\n",
      "\n",
      "    accuracy                           0.78       879\n",
      "   macro avg       0.59      0.51      0.50       879\n",
      "weighted avg       0.76      0.78      0.75       879\n",
      "\n",
      "AUC Score (OvR): 0.9022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "base_learners = [\n",
    "    ('naive_bayes', GaussianNB()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('adaboost', AdaBoostClassifier(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = stacking_clf.predict(X_test_scaled)\n",
    "y_proba = stacking_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search and CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Accuracy: 0.7964\n",
      "Confusion Matrix:\n",
      "[[560   1   3   2]\n",
      " [  6  12  16  42]\n",
      " [ 14   2  37  47]\n",
      " [ 18   5  23  91]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       566\n",
      "           1       0.60      0.16      0.25        76\n",
      "           2       0.47      0.37      0.41       100\n",
      "           3       0.50      0.66      0.57       137\n",
      "\n",
      "    accuracy                           0.80       879\n",
      "   macro avg       0.63      0.55      0.55       879\n",
      "weighted avg       0.79      0.80      0.78       879\n",
      "\n",
      "AUC Score (OvR): 0.9094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5, scoring='accuracy')\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "best_knn = knn_grid.best_estimator_\n",
    "\n",
    "adaboost_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "adaboost_grid = GridSearchCV(AdaBoostClassifier(), adaboost_param_grid, cv=5, scoring='accuracy')\n",
    "adaboost_grid.fit(X_train_scaled, y_train)\n",
    "best_adaboost = adaboost_grid.best_estimator_\n",
    "\n",
    "base_learners = [\n",
    "    ('naive_bayes', GaussianNB()),\n",
    "    ('knn', best_knn),\n",
    "    ('adaboost', best_adaboost)\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = stacking_clf.predict(X_test_scaled)\n",
    "y_proba = stacking_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB, knn and ada with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Accuracy: 0.7270\n",
      "Confusion Matrix:\n",
      "[[513  10  29  14]\n",
      " [  5  30  19  22]\n",
      " [ 10  23  32  35]\n",
      " [ 10  26  37  64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       566\n",
      "           1       0.34      0.39      0.36        76\n",
      "           2       0.27      0.32      0.29       100\n",
      "           3       0.47      0.47      0.47       137\n",
      "\n",
      "    accuracy                           0.73       879\n",
      "   macro avg       0.51      0.52      0.51       879\n",
      "weighted avg       0.75      0.73      0.74       879\n",
      "\n",
      "AUC Score (OvR): 0.8612\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "base_learners = [\n",
    "    ('naive_bayes', GaussianNB()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('adaboost', AdaBoostClassifier(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = stacking_clf.predict(X_test_scaled)\n",
    "y_proba = stacking_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search and CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Accuracy: 0.7429\n",
      "Confusion Matrix:\n",
      "[[518  13  21  14]\n",
      " [  8  27  15  26]\n",
      " [ 15  18  35  32]\n",
      " [ 16  18  30  73]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       566\n",
      "           1       0.36      0.36      0.36        76\n",
      "           2       0.35      0.35      0.35       100\n",
      "           3       0.50      0.53      0.52       137\n",
      "\n",
      "    accuracy                           0.74       879\n",
      "   macro avg       0.53      0.54      0.54       879\n",
      "weighted avg       0.75      0.74      0.75       879\n",
      "\n",
      "AUC Score (OvR): 0.8553\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5, scoring='accuracy')\n",
    "knn_grid.fit(X_train_scaled, y_train_resampled)\n",
    "best_knn = knn_grid.best_estimator_\n",
    "\n",
    "adaboost_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "adaboost_grid = GridSearchCV(AdaBoostClassifier(), adaboost_param_grid, cv=5, scoring='accuracy')\n",
    "adaboost_grid.fit(X_train_scaled, y_train_resampled)\n",
    "best_adaboost = adaboost_grid.best_estimator_\n",
    "\n",
    "base_learners = [\n",
    "    ('naive_bayes', GaussianNB()),\n",
    "    ('knn', best_knn),\n",
    "    ('adaboost', best_adaboost)\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = stacking_clf.predict(X_test_scaled)\n",
    "y_proba = stacking_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so RF, GB, XGB w/o smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model CV Accuracy: 0.9135\n",
      "Stacking Model Accuracy: 0.9192\n",
      "Confusion Matrix:\n",
      "[[563   0   1   2]\n",
      " [  7  39   8  22]\n",
      " [  4   4  89   3]\n",
      " [  8  10   2 117]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       566\n",
      "           1       0.74      0.51      0.60        76\n",
      "           2       0.89      0.89      0.89       100\n",
      "           3       0.81      0.85      0.83       137\n",
      "\n",
      "    accuracy                           0.92       879\n",
      "   macro avg       0.85      0.81      0.83       879\n",
      "weighted avg       0.91      0.92      0.91       879\n",
      "\n",
      "AUC Score (OvR): 0.9770\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=5, scoring='accuracy')\n",
    "gb_grid.fit(X_train_scaled, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "xgb_grid = GridSearchCV(XGBClassifier(), xgb_param_grid, cv=5, scoring='accuracy')\n",
    "xgb_grid.fit(X_train_scaled, y_train)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "base_learners = [\n",
    "    ('random_forest', best_rf),\n",
    "    ('gradient_boosting', best_gb),\n",
    "    ('xgboost', best_xgb)\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "stacking_cv_accuracy = cross_val_score(stacking_clf, X_train_scaled, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print(f\"Stacking Model CV Accuracy: {stacking_cv_accuracy:.4f}\")\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = stacking_clf.predict(X_test_scaled)\n",
    "y_proba = stacking_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so RF, GB, XGB with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model CV Accuracy: 0.9871\n",
      "Stacking Model Accuracy: 0.9181\n",
      "Confusion Matrix:\n",
      "[[560   3   0   3]\n",
      " [  6  40   4  26]\n",
      " [  4   4  89   3]\n",
      " [  6  11   2 118]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       566\n",
      "           1       0.69      0.53      0.60        76\n",
      "           2       0.94      0.89      0.91       100\n",
      "           3       0.79      0.86      0.82       137\n",
      "\n",
      "    accuracy                           0.92       879\n",
      "   macro avg       0.85      0.82      0.83       879\n",
      "weighted avg       0.91      0.92      0.92       879\n",
      "\n",
      "AUC Score (OvR): 0.9424\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train_scaled, y_train_resampled)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=5, scoring='accuracy')\n",
    "gb_grid.fit(X_train_scaled, y_train_resampled)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "xgb_grid = GridSearchCV(XGBClassifier(), xgb_param_grid, cv=5, scoring='accuracy')\n",
    "xgb_grid.fit(X_train_scaled, y_train_resampled)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "base_learners = [\n",
    "    ('random_forest', best_rf),\n",
    "    ('gradient_boosting', best_gb),\n",
    "    ('xgboost', best_xgb)\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "stacking_cv_accuracy = cross_val_score(stacking_clf, X_train_scaled, y_train_resampled, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print(f\"Stacking Model CV Accuracy: {stacking_cv_accuracy:.4f}\")\n",
    "\n",
    "stacking_clf.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred = stacking_clf.predict(X_test_scaled)\n",
    "y_proba = stacking_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes=np.unique(y_train_resampled))\n",
    "auc_score = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC Score (OvR): {auc_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
